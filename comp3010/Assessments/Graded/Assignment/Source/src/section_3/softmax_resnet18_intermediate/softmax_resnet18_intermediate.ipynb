{"cells":[{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"nhyGsi9-T77s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tB8ByySI7UuW"},"outputs":[],"source":["!pip install d2l==0.17.5"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":2,"tab":["pytorch"],"id":"F5LBjBuH7Uub"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","import torchvision.models as models\n","from torchvision import datasets, transforms as T\n","import torch.nn.functional as F\n","from d2l import torch as d2l"]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","  torch.cuda.empty_cache()\n","  device = torch.device('cuda')\n","else:\n","  device = torch.device('cpu')\n","\n","resnet18 = models.resnet18(pretrained=True).to(device)"],"metadata":{"id":"XultsritFpc7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":8,"id":"Y_RlahjV7Uud"},"source":["## Reading the Dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":9,"tab":["pytorch"],"id":"47MbwjvG7Uud"},"outputs":[],"source":["normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","transforms = T.Compose([T.Resize((224, 224)), T.ToTensor(), normalize])\n","\n","train_data = datasets.CIFAR10('train_data', download=True, transform=transforms)\n","test_data = datasets.CIFAR10('test_data', download=True, train=False, transform=transforms)\n","\n","batch_size = 256\n","\n","train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","source":["## Configuring Output Dimensions"],"metadata":{"id":"1dTaCaUdGns_"}},{"cell_type":"code","source":["def init_weights(model):\n","  nn.init.normal_(model.weight, std=0.01)\n","\n","out_layer = nn.Linear(200704, 10)\n","out_layer.apply(init_weights)"],"metadata":{"id":"RiMqqfSFGtLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet18.fc = out_layer"],"metadata":{"id":"FLA36OmEGukh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Feature Extraction"],"metadata":{"id":"pAoj040LTXT1"}},{"cell_type":"code","source":["class SoftmaxRegression(nn.Module):\n","  def __init__(self, input_dim, output_dim, *args, **kwargs):\n","    super(SoftmaxRegression, self).__init__()\n","    self.layer = nn.Linear(input_dim, output_dim)\n","\n","  def forward(self, X, *args, **kwargs):\n","    return F.softmax(self.layer(X), dim=-1)\n","\n","softmax = SoftmaxRegression(200704, 10)\n","\n","class CombineExtract(nn.Module):\n","  def __init__(self, pretrained_model, output_model, extract_layers):\n","    super(CombineExtract, self).__init__()\n","    self.pretrained = pretrained_model\n","    self.flatten = nn.Flatten()\n","    self.output = output_model\n","    self.inner_model = [getattr(self.pretrained, name) for name in extract_layers]\n","  \n","  def forward(self, x):\n","    for block in self.inner_model:\n","      x = block.forward(x)\n","    \n","    features = self.flatten.forward(x)\n","    return self.output.forward(features)\n","\n","extract_layers = ['conv1', 'bn1', 'relu', 'maxpool', 'layer1']\n","resnet_softmax = CombineExtract(resnet18, softmax, extract_layers)"],"metadata":{"id":"Y1UWAhSrT68Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":10,"id":"VjakYNzg7Uud"},"source":["## Training"]},{"cell_type":"code","source":["def train(net, train_iter, test_iter, num_epochs, lr, device):\n","    print('training on', device)\n","    net.to(device)\n","    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n","    loss = nn.CrossEntropyLoss()\n","    timer, num_batches = d2l.Timer(), len(train_iter)\n","    for epoch in range(num_epochs):\n","        # Sum of training loss, sum of training accuracy, no. of examples\n","        metric = d2l.Accumulator(3)\n","        net.train()\n","        for i, (X, y) in enumerate(train_iter):\n","            timer.start()\n","            optimizer.zero_grad()\n","            X, y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","            l = loss(y_hat, y)\n","            l.backward()\n","            optimizer.step()\n","            with torch.no_grad():\n","                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n","            timer.stop()\n","            train_l = metric[0] / metric[2]\n","            train_acc = metric[1] / metric[2]\n","        test_acc = evaluate(net, test_iter)\n","        print(f'epoch {epoch + 1}, loss {train_l:.3f}, train acc {train_acc:.3f}, '\n","          f'test acc {test_acc:.3f}')\n","    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n","          f'on {str(device)}')"],"metadata":{"id":"8MvHjD-THMYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(net, data_iter, device=None):\n","    if isinstance(net, nn.Module):\n","        net.eval()  # Set the model to evaluation mode\n","        if not device:\n","            device = next(iter(net.parameters())).device\n","    # No. of correct predictions, no. of predictions\n","    metric = d2l.Accumulator(2)\n","\n","    with torch.no_grad():\n","        for X, y in data_iter:\n","            if isinstance(X, list):\n","                # Required for BERT Fine-tuning\n","                X = [x.to(device) for x in X]\n","            else:\n","                X = X.to(device)\n","            y = y.to(device)\n","            metric.add(d2l.accuracy(net(X), y), y.numel())\n","    return metric[0] / metric[1]"],"metadata":{"id":"XctI5iWaHOc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":11,"tab":["pytorch"],"id":"asQxVt7i7Uud"},"outputs":[],"source":["learning_rate, num_epochs = 0.05, 10\n","value = train(resnet_softmax, train_data_loader, test_data_loader, num_epochs, learning_rate, d2l.try_gpu())"]}],"metadata":{"accelerator":"GPU","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"softmax_resnet18_intermediate.ipynb","provenance":[{"file_id":"https://github.com/d2l-ai/d2l-pytorch-colab/blob/master/chapter_convolutional-modern/alexnet.ipynb","timestamp":1652017928071}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}