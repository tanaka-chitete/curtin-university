{"cells":[{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"nhyGsi9-T77s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tB8ByySI7UuW"},"outputs":[],"source":["!pip install d2l==0.17.5"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":2,"tab":["pytorch"],"id":"F5LBjBuH7Uub"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","import torchvision.models as models\n","from torchvision import datasets, transforms as T\n","from d2l import torch as d2l"]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","  torch.cuda.empty_cache()\n","  device = torch.device('cuda')\n","else:\n","  device = torch.device('cpu')\n","\n","alexnet = models.alexnet(pretrained=True).to(device)"],"metadata":{"id":"XultsritFpc7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":8,"id":"Y_RlahjV7Uud"},"source":["## Reading the Dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":9,"tab":["pytorch"],"id":"47MbwjvG7Uud"},"outputs":[],"source":["normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","transforms = T.Compose([T.Resize((224, 224)), T.ToTensor(), normalize])\n","\n","train_data = datasets.CIFAR10('train_data', download=True, transform=transforms)\n","test_data = datasets.CIFAR10('test_data', download=True, train=False, transform=transforms)\n","\n","batch_size = 256\n","\n","train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","source":["## Configuring Output Dimensions"],"metadata":{"id":"1dTaCaUdGns_"}},{"cell_type":"code","source":["def init_weights(model):\n","  nn.init.normal_(model.weight, std=0.01)\n","\n","out_layer = nn.Linear(4096, 10)\n","out_layer.apply(init_weights)"],"metadata":{"id":"RiMqqfSFGtLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alexnet.classifier[6] = out_layer"],"metadata":{"id":"FLA36OmEGukh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":10,"id":"VjakYNzg7Uud"},"source":["## Training"]},{"cell_type":"code","source":["def train(net, train_iter, test_iter, num_epochs, lr, device):\n","    print('training on', device)\n","    net.to(device)\n","    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n","    loss = nn.CrossEntropyLoss()\n","    timer, num_batches = d2l.Timer(), len(train_iter)\n","    for epoch in range(num_epochs):\n","        # Sum of training loss, sum of training accuracy, no. of examples\n","        metric = d2l.Accumulator(3)\n","        net.train()\n","        for i, (X, y) in enumerate(train_iter):\n","            timer.start()\n","            optimizer.zero_grad()\n","            X, y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","            l = loss(y_hat, y)\n","            l.backward()\n","            optimizer.step()\n","            with torch.no_grad():\n","                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n","            timer.stop()\n","            train_l = metric[0] / metric[2]\n","            train_acc = metric[1] / metric[2]\n","        test_acc = evaluate(net, test_iter)\n","        print(f'epoch {epoch + 1}, loss {train_l:.3f}, train acc {train_acc:.3f}, '\n","          f'test acc {test_acc:.3f}')\n","    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n","          f'on {str(device)}')"],"metadata":{"id":"8MvHjD-THMYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(net, data_iter, device=None):\n","    if isinstance(net, nn.Module):\n","        net.eval()  # Set the model to evaluation mode\n","        if not device:\n","            device = next(iter(net.parameters())).device\n","    # No. of correct predictions, no. of predictions\n","    metric = d2l.Accumulator(2)\n","\n","    with torch.no_grad():\n","        for X, y in data_iter:\n","            if isinstance(X, list):\n","                # Required for BERT Fine-tuning\n","                X = [x.to(device) for x in X]\n","            else:\n","                X = X.to(device)\n","            y = y.to(device)\n","            metric.add(d2l.accuracy(net(X), y), y.numel())\n","    return metric[0] / metric[1]"],"metadata":{"id":"XctI5iWaHOc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":11,"tab":["pytorch"],"id":"asQxVt7i7Uud"},"outputs":[],"source":["learning_rate, num_epochs = 0.01, 10\n","train(alexnet, train_data_loader, test_data_loader, num_epochs, learning_rate, d2l.try_gpu())"]}],"metadata":{"accelerator":"GPU","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"alexnet.ipynb","provenance":[{"file_id":"https://github.com/d2l-ai/d2l-pytorch-colab/blob/master/chapter_convolutional-modern/alexnet.ipynb","timestamp":1652017928071}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}